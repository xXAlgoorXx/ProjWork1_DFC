{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DFC compiler\n",
    "\n",
    "This file is used to compile a onnx file into a hef file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onnx to har"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 11:01:16.228232: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-21 11:01:16.229308: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-21 11:01:16.250199: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-21 11:01:16.250794: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-21 11:01:16.644631: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17.0\n",
      "[info] Translation started on ONNX model RN50x4\n",
      "[info] Restored ONNX model RN50x4 (completion time: 00:00:00.70)\n",
      "[info] Extracted ONNXRuntime meta-data for Hailo model (completion time: 00:00:03.89)\n",
      "[info] Simplified ONNX model for a parsing retry attempt (completion time: 00:00:07.16)\n",
      "[info] Start nodes mapped from original model: 'modelInput': 'RN50x4/input_layer1'.\n",
      "[info] End nodes mapped from original model: '/attnpool/Squeeze'.\n",
      "[info] Translation completed on ONNX model RN50x4 (completion time: 00:00:07.72)\n",
      "[info] Saved HAR to: /home/lukasschoepf/Documents/hailoDFC/Harfiles/RN50x4_hailo_model.har\n"
     ]
    }
   ],
   "source": [
    "# General imports used throughout the tutorial\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "from pathlib import Path\n",
    "\n",
    "modelPath = Path(\"models\")\n",
    "# import the ClientRunner class from the hailo_sdk_client package\n",
    "from hailo_sdk_client import ClientRunner\n",
    "import onnx\n",
    "print(onnx.__version__)\n",
    "chosen_hw_arch = \"hailo8\"\n",
    "\n",
    "onnx_model_name = \"RN50x4\"\n",
    "onnx_path = modelPath / f\"{onnx_model_name}.onnx\"\n",
    "\n",
    "runner = ClientRunner(hw_arch=chosen_hw_arch)\n",
    "\n",
    "hn, npz = runner.translate_onnx_model(\n",
    "    onnx_path,\n",
    "    onnx_model_name,\n",
    "    # start_node_names=[\"modelInput\"],\n",
    "    # end_node_names=[\"modelOutput\"],\n",
    "    # disable_rt_metadata_extraction=True,\n",
    "    # disable_shape_inference=True,\n",
    "    # net_input_shapes={\"modelInput\": [1, 3, 224, 224]}\n",
    ")\n",
    "\n",
    "hailo_model_har_name = f\"Harfiles/{onnx_model_name}_hailo_model.har\"\n",
    "runner.save_har(hailo_model_har_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Har to har(optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports used throughout the tutorial\n",
    "# file operations\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "from matplotlib import patches\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.python.eager.context import eager_mode\n",
    "\n",
    "# import the hailo sdk client relevant classes\n",
    "from hailo_sdk_client import ClientRunner, InferenceContext\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# preprocessing\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess\n",
    "\n",
    "For optimization a dataset is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "def transform(n_px):\n",
    "    \"\"\"\n",
    "    n_px: input resolution of the network\n",
    "    \"\"\"\n",
    "    return Compose([\n",
    "        Resize(n_px, interpolation=BICUBIC),\n",
    "        CenterCrop(n_px),\n",
    "        _convert_image_to_rgb,\n",
    "        ToTensor(),\n",
    "        Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "    ])\n",
    "\n",
    "# First, we will prepare the calibration set. Resize the images to the correct size and crop them.\n",
    "def preproc(image, output_height=224, output_width=224, resize_side=256):\n",
    "    \"\"\"imagenet-standard: aspect-preserving resize to 256px smaller-side, then central-crop to 224px\"\"\"\n",
    "    with eager_mode():\n",
    "        h, w = image.shape[0], image.shape[1]\n",
    "        scale = tf.cond(tf.less(h, w), lambda: resize_side / h, lambda: resize_side / w)\n",
    "        resized_image = tf.compat.v1.image.resize_bilinear(tf.expand_dims(image, 0), [int(h * scale), int(w * scale)])\n",
    "        cropped_image = tf.compat.v1.image.resize_with_crop_or_pad(resized_image, output_height, output_width)\n",
    "\n",
    "        return tf.squeeze(cropped_image)\n",
    "\n",
    "preprocess = transform(224)\n",
    "images_path = \"../data\"\n",
    "images_list = [img_name for img_name in os.listdir(images_path) if os.path.splitext(img_name)[1] == \".jpg\"]\n",
    "\n",
    "calib_dataset = np.zeros((len(images_list), 224, 224, 3))\n",
    "for idx, img_name in enumerate(sorted(images_list)):\n",
    "    img = np.array(Image.open(os.path.join(images_path, img_name)))\n",
    "    img_preproc = preproc(img)\n",
    "    calib_dataset[idx, :, :, :] = img_preproc.numpy()\n",
    "\n",
    "np.save(\"calib_set.npy\", calib_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, we will load our parsed HAR from the Parsing Tutorial\n",
    "\n",
    "model_name = \"resnet_v1_18\"\n",
    "hailo_model_har_name = f\"{model_name}_hailo_model.har\"\n",
    "assert os.path.isfile(hailo_model_har_name), \"Please provide valid path for HAR file\"\n",
    "runner = ClientRunner(har=hailo_model_har_name)\n",
    "# By default it uses the hw_arch that is saved on the HAR. For overriding, use the hw_arch flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will create a model script, that tells the compiler to add a normalization on the beginning\n",
    "# of the model (that is why we didn't normalize the calibration set;\n",
    "# Otherwise we would have to normalize it before using it)\n",
    "\n",
    "# Batch size is 8 by default\n",
    "alls = \"normalization1 = normalization([123.675, 116.28, 103.53], [58.395, 57.12, 57.375])\\n\"\n",
    "\n",
    "# Load the model script to ClientRunner so it will be considered on optimization\n",
    "runner.load_model_script(alls)\n",
    "\n",
    "# Call Optimize to perform the optimization process\n",
    "runner.optimize(calib_dataset)\n",
    "\n",
    "# Save the result state to a Quantized HAR file\n",
    "quantized_model_har_path = f\"{model_name}_quantized_model.har\"\n",
    "runner.save_har(quantized_model_har_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Har(optimized) to hef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hailo_sdk_client import ClientRunner\n",
    "\n",
    "model_name = \"RN50x4\"\n",
    "quantized_model_har_path = modelPath / f\"{model_name}_quantized_model.har\"\n",
    "\n",
    "runner = ClientRunner(har=quantized_model_har_path)\n",
    "# By default it uses the hw_arch that is saved on the HAR. It is not recommended to change the hw_arch after Optimization.\n",
    "\n",
    "hef = runner.compile()\n",
    "\n",
    "file_name = f\"{model_name}.hef\"\n",
    "with open(file_name, \"wb\") as f:\n",
    "    f.write(hef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "har_path = f\"{model_name}_compiled_model.har\"\n",
    "runner.save_har(har_path)\n",
    "!hailo profiler {har_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hailodfc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
